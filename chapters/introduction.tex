\addchap{Introduction}

% \lehead{Silvia Hansen-Schirra, Oliver Czulo \& Sascha Hofmann}
\rohead{Silvia Hansen-Schirra, Oliver Czulo \& Sascha Hofmann}
\begin{refsection}

According to \citet{Black1999}, empirical research is carried out in a cyclic way: approaching a research area bottom-up, data lead to interpretations and ideally to the abstraction of laws, on the basis of which a theory can be derived. Deductive research is based on a theory, on the basis of which hypotheses can be formulated and tested against the background of empirical data. Looking at the state-of-the-art in translation studies, either theories/models are designed or empirical data are collected and interpreted. However, the completion of a scientific circle by deriving hypotheses from existing theories or by drafting models and testing them on the basis of empirical data, which can then be generalized and fed back into the theoretical framework, can only rarely be found in translation studies. First exceptions are for instance \citet{deSutter2017} who link new empirical methods to theoretical traditions, or \citet{Alves2013} who investigate translation units on the basis of relevance theoretical considerations. Another example would be \citet{PACTE2014} who operationalize their competence model and test it with empirical insights. In the area of translation \isi{process research}, the comprehensive operationalization in terms of the scientific circle is still lacking. 

From a methodological point of view, using empirical methods for the investigation of translation and \isi{interpreting} phenomena has been an issue for quite some time with a surge of research over the last two decades. While example-based analyses of small numbers of source texts and their translations are still used to generate hypotheses, many studies profit from empirical data in order to test hypotheses, quantify findings and generalize interpretations. Finally, the following questions have to be dealt with having the comprehensiveness of the scientific circle in mind: how can we systematically operationalize a translation model or theory in terms of testable variables, i.e. how can we assess a theory or a model by means of data? Or the other way around: how can empirical data be integrated in such a way that they result in a model or theory? Concerning these questions, methods and techniques from translation \isi{process research} can be applied, as well as from product-oriented research, or combinations of both. 

So far, product-oriented translation research has provided us with quantifications of translation phenomena without giving insights into explanatory backgrounds. Process-based research allows drawing conclusions on explanations but in most cases lacks empirical evidence in form of significance testing. Therefore, the integration of product- and process-based translation research seems a promising goal in translation studies – including offline methods (retrospective interviews, comprehensibility ratings, etc.) as well as online methods (keylogging, eyetracking, thinking aloud, etc., see e.g. \citealt{Krings2005}). Gyde \citet{Hansen2002} as well as Fabio \citet{Alves:2003va} were among the first to propose empirically-based approaches tackling some of the challenges posed by dealing with both process and product data. This kind of data \isi{triangulation} has to be further elaborated in order to yield further insights into the cognitive processes involved in translation. 

However, some problems have to be coped with: We have to face the consequence that multi-method approaches, which are necessary as a basis for data \isi{triangulation}, produce a huge amount of data, which cannot straightforwardly be interpreted in terms of previously formulated hypotheses. Therefore, models have to be found on the basis of data that can be investigated and interpreted in a systematical and comprehensive way. As another consequence, statistical tests have to be carried out in order to differentiate incidental findings from significant results. The different kinds of data have to be mapped onto each other. When dealing with translation corpora, alignment units are, for instance, not trivial to define: compounds, contractions, differing tense systems, etc. lead to segmentation problems across languages. The more annotation layers are included, the more complex this mapping problem becomes. If, for example, eye-tracking and key-logging data have to be mapped, time stamps might help to parallelize the different processing units. If, however, eye-tracking and key-logging are to be combined with linguistic annotation layers (e.g. on semantic relations or syntactic functions), the time stamps have to be mapped onto word indexes or vice versa, which is not trivial at all.

This volume consists of papers selected from contributions to the 2013 conference of the \textit{European Society for Translation Studies} (EST 2013) and the 2015 edition of the Translation in Transition conference (TiT 2015), both held at the Faculty for Translation Studies, Linguistics and Cultural Studies of the University of Mainz in Germersheim, Germany. It addresses the above-mentioned issues from several perspectives: multi-method product- as well as process-based research gives insights into translation as well as \isi{interpreting} phenomena. These phenomena may include cognitive and organizational processes, procedures and strategies, competence and performance, translation properties and \isi{universals}, etc. Empirical findings about the deeper structures of translation and \isi{interpreting} will reduce the gap between translation and \isi{interpreting} data and model and theory building. Furthermore, the availability of more large-scale empirical testing triggers the development of models and theories concerning translation and \isi{interpreting} phenomena and behavior based on quantifiable, replicable and transparent data.\\

\bigskip{}
\noindent Germersheim and Leipzig, November 2017\\
\noindent Silvia Hansen-Schirra, Oliver Czulo, Sascha Hofmann

% According to \citet[23]{Black1999} empirical research is carried out in a cyclic way: approaching a research area bottom-up, data lead to interpretations and ideally to the abstraction of laws, on the basis of which a theory can be derived. Deductive research is based on a theory, on the basis of which hypotheses can be formulated and tested against the background of empirical data. Looking at the state-of-the-art in translation studies, either theories as well as models are designed or empirical data are collected and interpreted. However, the final step is still lacking: so far, empirical data has not lead to the formulation of theories or models, whereas existing theories and models have not yet been comprehensively tested with empirical methods (for first results see \citet[23]{PACTE2014}).

% From a methodological point of view, using empirical methods for the investigation of translation and \isi{interpreting} phenomena has been an issue for quite some time with a surge of research over the last two decades. While example-based analyses of small numbers of source texts and their translations are still used to generate hypotheses, many studies profit from empirical data in order to test hypotheses, quantify findings and generalize interpretations. Finally, the following questions have to be dealt with: how can we systematically operationalize a translation model or theory in terms of testable variables, i.e. how can be measure contents of a theory or a model? Or the other way around: how can empirical data be integrated in such a way that they result in a model or theory? Concerning these questions, methods and techniques from translation \isi{process research} can be applied: product-oriented research, process-oriented research as well as combinations of both. 

% So far, product-oriented translation research has provided us with quantifications of translation phenomena without giving insights into explanatory backgrounds. However, process-based research allows drawing conclusions on explanations but in most cases lacks empirical evidence in form of significance testing. Therefore, the integration of product- and process-based translation research seems a promising goal in translation studies – including offline methods (retrospective interviews, comprehensibility ratings, etc.) as well as online methods (keylogging, eyetracking, thinking aloud, etc.) \citep{Krings2005}. Gyde \citet{Hansen2002} was among the first to propose an empirically-based approach to integration in a collection of articles tackling some of the challenges posed in dealing with process and product data. This kind of data \isi{triangulation} has to be further elaborated in order to yield further insights into the cognitive processes involved in translation. 

% However, some problems have to be coped with: We have to face the consequence that the multi-method approaches, which are necessary as a basis for data \isi{triangulation}, produce a huge amount of data, which cannot straightforwardly be interpreted in terms of previously formulated hypotheses. Therefore, models have to be found on the basis of which the different kinds of data can be investigated and interpreted in a systematical and comprehensive way. As another consequence, statistical tests have to be carried out in order to differentiate incidental findings from significant results. The different kinds of data have to be mapped onto each other. When dealing with translation corpora, alignment units are, for instance, not trivial to define: compounds, contractions, differing tense systems, etc. lead to segmentation problems across languages. The more annotation layers are included, the more complex this mapping problem becomes. If, for example, eye-tracking and key-logging data have to be mapped, time stamps might help to parallelize the different processing units. If, however, eye-tracking and key-logging are to be combined with linguistic annotation layers (e.g. on semantic relations or syntactic functions) the time stamps have to be mapped onto word indexes or vice versa, which is not trivial at all. 

% This publication addresses these issues from several perspectives: multi-method product- as well as process-based research may gain insights into translation as well as \isi{interpreting} phenomena. These phenomena may include cognitive and organizational processes, procedures and strategies, competence and performance, translation properties and \isi{universals}, etc. Empirical findings about the deeper structures of translation and \isi{interpreting} will reduce the gap between translation and \isi{interpreting} practice and model and theory building. Furthermore, the availability of more large-scale empirical testing triggers the development of models and theories concerning translation and \isi{interpreting} phenomena and behavior based on quantifiable, replicable and transparent data. 

\sloppy
\printbibliography[heading=subbibliography,notkeyword=this]
\end{refsection}
